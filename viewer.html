<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>View PDF with Chunked LocalStorage</title>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      height: 100%;
      overflow: hidden;
    }
    #pdfEmbed {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      border: none;
    }
  </style>
  <script>
    const CHUNK_SIZE = 200 * 1024; // 200 KB

    // Get query parameters
    function getUrlParams() {
      const params = new URLSearchParams(window.location.search);
      return {
        fileName: params.get('fileName') || 'default.pdf',
        startIdx: parseInt(params.get('startIdx')) || 1,
        endIdx: parseInt(params.get('endIdx')) || 1,
      };
    }

    // Generate a random page within the startIdx and endIdx
    function getRandomPage(startIdx, endIdx) {
      return Math.floor(Math.random() * (endIdx - startIdx + 1)) + startIdx;
    }

    // Embed the PDF (data URL or direct file) with a specific page
    function showPdf(srcUrl, pageNumber) {
      document.getElementById('pdfEmbed').src = srcUrl + '#page=' + pageNumber;
    }

    // If storing or reassembling fails, revert to showing the PDF from the original source
    function revertToOriginal(fileName, pageNumber) {
      console.warn('Reverting to original PDF source...');
      showPdf(fileName, pageNumber);
    }

    // Store the PDF as multiple base64-encoded chunks in localStorage
    async function storePdfChunks(fileName, blob) {
      // Convert to ArrayBuffer
      const arrayBuffer = await blob.arrayBuffer();
      const byteArray = new Uint8Array(arrayBuffer);

      // Calculate number of chunks
      const totalChunks = Math.ceil(byteArray.length / CHUNK_SIZE);

      // Remove old chunks if they exist
      clearPdfChunks(fileName);

      for (let i = 0; i < totalChunks; i++) {
        const start = i * CHUNK_SIZE;
        const end = Math.min(start + CHUNK_SIZE, byteArray.length);
        // Slice out this chunk
        const chunk = byteArray.slice(start, end);
        // Convert chunk to base64
        const base64Chunk = await arrayBufferToBase64(chunk);
        // Store in localStorage
        localStorage.setItem(`${fileName}-chunk-${i}`, base64Chunk);
      }
      // Store metadata: number of chunks
      localStorage.setItem(`${fileName}-chunk-count`, totalChunks.toString());
    }

    // Clear any old chunks for a file
    function clearPdfChunks(fileName) {
      const chunkCount = parseInt(localStorage.getItem(`${fileName}-chunk-count`) || '0', 10);
      for (let i = 0; i < chunkCount; i++) {
        localStorage.removeItem(`${fileName}-chunk-${i}`);
      }
      localStorage.removeItem(`${fileName}-chunk-count`);
    }

    // Convert a small Uint8Array chunk to base64 string
    function arrayBufferToBase64(u8Arr) {
      return new Promise((resolve, reject) => {
        try {
          const reader = new FileReader();
          reader.onloadend = () => {
            // "reader.result" will be something like: "data:application/octet-stream;base64,...."
            // We only want the base64 part after the comma
            const resultStr = reader.result;
            resolve(resultStr);
          };
          reader.readAsDataURL(new Blob([u8Arr]));
        } catch (err) {
          reject(err);
        }
      });
    }

    // Attempt to reassemble all chunks into a single base64 data URL for embedding
    async function reassemblePdf(fileName) {
      const chunkCount = parseInt(localStorage.getItem(`${fileName}-chunk-count`) || '0', 10);
      if (!chunkCount) return null;

      // We'll decode each chunk from a "data:...base64," URL to raw bytes,
      // then combine them all into one large Uint8Array, and build a final data URL.
      let totalBytes = 0;
      const chunkArrays = [];

      for (let i = 0; i < chunkCount; i++) {
        const base64Url = localStorage.getItem(`${fileName}-chunk-${i}`);
        if (!base64Url) {
          console.warn('Missing chunk ' + i + ' in localStorage');
          return null;
        }
        const byteArray = await base64UrlToUint8Array(base64Url);
        chunkArrays.push(byteArray);
        totalBytes += byteArray.length;
      }

      // Combine all chunks into one array
      const combined = new Uint8Array(totalBytes);
      let offset = 0;
      for (const arr of chunkArrays) {
        combined.set(arr, offset);
        offset += arr.length;
      }

      // Convert the combined array to a single base64 PDF data URL
      return uint8ArrayToDataUrl(combined);
    }

    // Convert a base64 data URL back into a Uint8Array
    function base64UrlToUint8Array(base64Url) {
      return new Promise((resolve, reject) => {
        try {
          // Create a Blob from the data URL
          fetch(base64Url)
            .then(res => res.blob())
            .then(blob => blob.arrayBuffer())
            .then(buffer => {
              resolve(new Uint8Array(buffer));
            })
            .catch(err => reject(err));
        } catch (err) {
          reject(err);
        }
      });
    }

    // Convert a Uint8Array to a base64 data URL (with PDF MIME type)
    function uint8ArrayToDataUrl(u8Arr) {
      return new Promise((resolve, reject) => {
        try {
          const blob = new Blob([u8Arr], { type: 'application/pdf' });
          const reader = new FileReader();
          reader.onloadend = () => {
            resolve(reader.result); // data:application/pdf;base64,...
          };
          reader.readAsDataURL(blob);
        } catch (err) {
          reject(err);
        }
      });
    }

    async function displayPdf() {
      const { fileName, startIdx, endIdx } = getUrlParams();
      const randomPage = getRandomPage(startIdx, endIdx);

      // Try to reassemble from localStorage first
      try {
        const dataUrl = await reassemblePdf(fileName);
        if (dataUrl) {
          // If we successfully reassembled it, display from localStorage
          showPdf(dataUrl, randomPage);
          return;
        }
      } catch (err) {
        console.warn('Failed to reassemble PDF from chunks:', err);
      }

      // If not in localStorage or reassembly fails, fetch from network
      fetch(fileName)
        .then(response => {
          if (!response.ok) {
            throw new Error('Network response was not ok: ' + response.statusText);
          }
          return response.blob();
        })
        .then(async blob => {
          try {
            // Try storing in localStorage as chunks
            await storePdfChunks(fileName, blob);

            // Confirm it was stored properly by reassembling
            const reassembled = await reassemblePdf(fileName);
            if (!reassembled) {
              console.warn('Failed to confirm reassembled PDF. Reverting to original.');
              revertToOriginal(fileName, randomPage);
              return;
            }
            // If all good, display from chunked localStorage
            showPdf(reassembled, randomPage);
          } catch (error) {
            // Usually QUOTA_EXCEEDED_ERR or other chunking error
            console.error('Failed to store in localStorage:', error);
            // Revert to original
            revertToOriginal(fileName, randomPage);
          }
        })
        .catch(error => {
          console.error('Error fetching or reading PDF:', error);
          // If fetch fails, revert to original process
          revertToOriginal(fileName, randomPage);
        });
    }
  </script>
</head>
<body onload="displayPdf()">
  <embed id="pdfEmbed" src="" type="application/pdf" />
</body>
</html>
